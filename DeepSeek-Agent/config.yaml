# DeepSeek-Agent Configuration

# Vision Encoder Settings
vision_encoder:
  model_path: "deepseek-ai/DeepSeek-OCR"
  frozen: true
  output_dim: 2048
  device: "mps"
  dtype: "float16"

# Vision Projector Settings
projector:
  in_dim: 2048
  out_dim: 4096
  hidden_dim: 4096
  freeze_after_stage_a: true
  use_layer_norm: true
  use_modality_embedding: true

# Vision Token Compressor (Optional)
compressor:
  enabled: true
  num_output_tokens: 32
  hidden_dim: 4096
  num_heads: 8
  dropout: 0.1

# LLM Configuration
llm:
  model_name: "ibm/granite-7b-1m-instruct"
  # Alternative: "Qwen/Qwen2-7B-Instruct"
  device: "mps"
  dtype: "float16"
  max_context_length: 1000000
  load_in_8bit: false
  # load_in_4bit: true  # Uncomment for extreme memory constraints

# Memory and Retrieval
memory:
  max_screens: 1000
  embedding_dim: 4096
  similarity_threshold: 0.7
  retrieval_top_k: 3
  faiss_metric: "L2"  # or "cosine"
  use_gpu: false

# Data Configuration
data:
  screenshot_save_dir: "logs/screenshots"
  tokens_save_dir: "logs/tokens"
  metadata_save_dir: "logs/metadata"
  max_screenshots_per_task: 500
  screenshot_format: "png"
  token_dtype: "float32"

# Training Configuration - Stage 1: Projector Alignment
training:
  projector:
    batch_size: 64
    accumulation_steps: 2
    learning_rate: 1e-3
    weight_decay: 0.0
    epochs: 1
    warmup_steps: 2000
    max_grad_norm: 1.0
    num_workers: 16
    pin_memory: false
    use_amp: true  # Automatic mixed precision
    
  # Stage 2: Agent LoRA Finetuning
  agent_lora:
    enabled: false  # Set to true after Stage 1
    batch_size: 16
    accumulation_steps: 4
    learning_rate: 5e-4
    lora_rank: 8
    lora_alpha: 16
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]
    epochs: 2
    warmup_steps: 1000
    max_grad_norm: 1.0
    use_amp: true

# Agent Configuration
agent:
  max_steps: 20
  step_timeout_sec: 30
  action_types: ["click", "type", "scroll", "wait", "navigate"]
  use_memory_retrieval: true
  memory_context_limit: 3
  temperature: 0.7
  top_p: 0.9
  max_new_tokens: 256

# Data Collection
data_collection:
  fps: 2  # Screenshot frames per second
  max_duration_sec: 300
  annotate_manually: true
  auto_detect_clicks: false  # Could use heuristics
  save_raw_video: false

# Checkpoints and Logging
checkpoint:
  save_dir: "checkpoints"
  save_frequency: 100  # Save every N batches
  keep_best_only: true
  best_metric: "val_loss"

logging:
  log_dir: "logs"
  log_level: "INFO"
  save_frequency: 10
  tensorboard_enabled: true
  wandb_enabled: false

# Device and Performance
hardware:
  device: "mps"  # or "cpu"
  num_gpus: 0
  mixed_precision: "fp16"
  torch_compile: false
  num_workers: 16
  pin_memory: false
